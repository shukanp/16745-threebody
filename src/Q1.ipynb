{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.activate(joinpath(@__DIR__,\"..\")); Pkg.instantiate();\n",
    "using LinearAlgebra\n",
    "using ForwardDiff\n",
    "using Test\n",
    "include(joinpath(@__DIR__,\"utils.jl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-footage",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 1: Automatic Differentiation in Julia (7 pts)\n",
    "Julia has a fast and easy to use forward-mode automatic differentiation package called [ForwardDiff.jl](https://github.com/JuliaDiff/ForwardDiff.jl) that we will make use of throughout this course. In general it is easy to use and very fast, but there are a few quirks that are detailed below. This notebook will start by walking through general usage for the following cases:\n",
    "- functions with a single input \n",
    "- functions with multiple inputs\n",
    "- composite functions\n",
    "\n",
    "as well as a guide on how to avoid the most common ForwardDiff.jl error caused by creating arrays inside the function being differentiated. First, let's look at the ForwardDiff.jl functions that we are going to use:\n",
    "- `derivative(f,x)` derivative of scalar or vector valued f wrt scalar x \n",
    "- `jacobian(f,x)` jacobian of vector valued f wrt vector x\n",
    "- `gradient(f,x)` gradient of scalar valued f wrt vector x \n",
    "- `hessian(f,x)` hessian of scalar valued f wrt vector x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-wheel",
   "metadata": {},
   "source": [
    "### Note on gradients:\n",
    "For an arbitrary function $f(x):\\mathbb{R}^N \\rightarrow \\mathbb{R}^M$, the jacobian is the following:\n",
    "\n",
    "\n",
    "$$\\frac{\\partial f(x)}{\\partial x} = \\left[\\begin{array}{ccc}\n",
    "\\frac{\\partial f_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{1}}{\\partial x_{n}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{m}}{\\partial x_{n}}\n",
    "\\end{array}\\right] $$\n",
    "\n",
    "\n",
    "Now if we have a scalar valued function (like a cost function) $f(x):\\mathbb{R}^N \\rightarrow \\mathbb{R}$, the jacobian is the following row vector:\n",
    "\n",
    "$$\\frac{\\partial f(x)}{\\partial x} = \\left[\\begin{array}{ccc}\n",
    "\\frac{\\partial f_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{1}}{\\partial x_{n}}\n",
    "\\end{array}\\right] $$\n",
    "\n",
    "The transpose of this jacobian for scalar valued functions is called the gradient:\n",
    "\n",
    "$$ \\nabla f(x) = \\bigg[\\frac{\\partial f(x)}{\\partial x}\\bigg]^T $$\n",
    "\n",
    "TLDR:\n",
    "- the jacobian of a scalar value function is a row vector \n",
    "- the gradient is the transpose of this jacobian, making the gradient a column vector \n",
    "- ForwardDiff.jl will give you an error if you try to take a jacobian of a scalar valued function, use the gradient function instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-blond",
   "metadata": {},
   "source": [
    "## Part (a): General usage (2 pts)\n",
    "The API for functions with one input is detailed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this block is a tutorial, you do not have to fill anything out. \n",
    "\n",
    "function foo1(x)\n",
    "    #scalar input, scalar output\n",
    "    return sin(x)*cos(x)^2\n",
    "end\n",
    "\n",
    "function foo2(x)\n",
    "    # vector input, scalar output\n",
    "    return sin(x[1]) + cos(x[2])\n",
    "end\n",
    "function foo3(x)\n",
    "    # vector input, vector output\n",
    "    return [sin(x[1])*x[2];cos(x[2])*x[1]]\n",
    "end\n",
    "\n",
    "\n",
    "let # we just use this to avoid creating global variables\n",
    "    \n",
    "    # evaluate the derivative of foo1 at x1\n",
    "    x1 = 5*randn();\n",
    "    @show ∂foo1_∂x = ForwardDiff.derivative(foo1, x1);\n",
    "    \n",
    "    # evaluate the gradient and hessian of foo2 at x2\n",
    "    x2 = 5*randn(2);\n",
    "    @show ∇foo2 = ForwardDiff.gradient(foo2, x2);\n",
    "    @show ∇²foo2 = ForwardDiff.hessian(foo2, x2);\n",
    "    \n",
    "    # evluate the jacobian of foo3 at x2\n",
    "    @show ∂foo3_∂x = ForwardDiff.jacobian(foo3,x2);\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is our function of interest\n",
    "function foo4(x)\n",
    "    Q = diagm([1;2;3.0])\n",
    "    return 0.5*x'*Q*x/x[1] - log(x[1])*exp(x[2])^x[3] \n",
    "end\n",
    "\n",
    "function foo4_expansion(x)\n",
    "    # TODO: this function should output the hessian H and gradient g of the function foo4\n",
    "    \n",
    "    # TODO: calculate the gradient of foo4 evaluated at x\n",
    "    g = zeros(length(x))\n",
    "    \n",
    "    # TODO: calculate the hessian of foo4 evaluated at x\n",
    "    H = zeros(length(x),length(x))\n",
    "    \n",
    "    return g, H\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"1a\" begin                        # POINTS = 2\n",
    "    x = [.2;.4;.5]\n",
    "    g,H = foo4_expansion(x)\n",
    "    @test isapprox(g,[-18.98201379080085, 4.982885952667278, 8.286308762133823],atol = 1e-8)        # POINTS = 1\n",
    "    @test matrix_isapprox(H,[164.2850689540042 -23.053506895400425 -39.942805516320334; -23.053506895400425 10.491442976333639 2.3589262864014673; -39.94280551632034 2.3589262864014673 15.314523504853529];atol = 1e-8) # POINTS = 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-shade",
   "metadata": {},
   "source": [
    "## Part (b): Derivatives for functions with multiple input arguments (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this block is a tutorial, you do not have to fill anything out. \n",
    "\n",
    "# calculate derivatives for functions with multiple inputs \n",
    "function dynamics(x,a,b,c)\n",
    "    return [x[1]*a; b*c*x[2]*x[1]]\n",
    "end\n",
    "\n",
    "let \n",
    "    x1 = randn(2)\n",
    "    a = randn()\n",
    "    b = randn()\n",
    "    c = randn()\n",
    "    \n",
    "    # this evaluates the jacobian with respect to x, given a, b, and c\n",
    "    A = ForwardDiff.jacobian(dx -> dynamics(dx, a, b, c), x1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "function eulers(x,u,J)\n",
    "    # dynamics when x is angular velocity and u is an input torque\n",
    "    ẋ = J\\(u - cross(x,J*x))\n",
    "    return ẋ\n",
    "end\n",
    "\n",
    "function eulers_jacobians(x,u,J)\n",
    "    # given x, u, and J, calculate the following two jacobians \n",
    "    \n",
    "    # TODO: fill in the following two jacobians\n",
    "    \n",
    "    # ∂ẋ/∂x\n",
    "    A = zeros(3,3)\n",
    "    \n",
    "    # ∂ẋ/∂u\n",
    "    B = zeros(3,3)\n",
    "    \n",
    "    return A, B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"1b\" begin                                                # POINTS = 2\n",
    "    \n",
    "    x = [.2;-7;.2]\n",
    "    u = [.1;-.2;.343]\n",
    "    J = diagm([1.03;4;3.45])\n",
    "    \n",
    "    A,B = eulers_jacobians(x,u,J)\n",
    "\n",
    "    @test isapprox(A,-J\\(skew(x)*J - skew(J*x)), atol = 1e-8)  # POINTS = 1 \n",
    "\n",
    "    @test matrix_isapprox(B,inv(J),atol = 1e-8)                # POINTS = 1 \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-technique",
   "metadata": {},
   "source": [
    "## Part (c): Derivatives of composite functions (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this block is a tutorial, you do not have to fill anything out. \n",
    "function f(x)\n",
    "    return x[1]*x[2]\n",
    "end\n",
    "function g(x)\n",
    "    return [x[1]^2; x[2]^3]\n",
    "end\n",
    "\n",
    "let \n",
    "    x1 = 2*randn(2)\n",
    "    \n",
    "    # using gradient of the composite function\n",
    "    ∇f_1 = ForwardDiff.gradient(dx -> f(g(dx)), x1)\n",
    "    \n",
    "    # using the chain rule \n",
    "    J = ForwardDiff.jacobian(g, x1)\n",
    "    ∇f_2 = J'*ForwardDiff.gradient(f, g(x1))\n",
    "    \n",
    "    @show norm(∇f_1 - ∇f_2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f2(x)\n",
    "    return x*sin(x)/2\n",
    "end\n",
    "function g2(x)\n",
    "    return cos(x)^2 - tan(x)^3\n",
    "end\n",
    "\n",
    "function composite_derivs(x)\n",
    "    \n",
    "    # TODO: return ∂y/∂x where y = g2(f2(x)) \n",
    "    # (hint: this is 1D input and 1D output, so it's ForwardDiff.derivative)\n",
    "    return NaN\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"1c\" begin                                           # POINTS = 1\n",
    "    x = 1.34 \n",
    "    deriv = composite_derivs(x)\n",
    "\n",
    "    @test isapprox(deriv,-2.390628273373545,atol = 1e-8)  # POINTS = 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-injection",
   "metadata": {},
   "source": [
    "## Part (d): Fixing the most common ForwardDiff error (2 pt)\n",
    "First we will show an example of this error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-master",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: this block is a tutorial, you do not have to fill anything out. \n",
    "function f_zero_1(x)\n",
    "    \n",
    "    # diffing through this function will error on this line \n",
    "    xdot = zeros(length(x))\n",
    "    \n",
    "    xdot[1] = x[1]*x[2]\n",
    "    xdot[2] = x[2]^2\n",
    "    \n",
    "    return xdot \n",
    "end\n",
    "\n",
    "let \n",
    "    # try and calculate the jacobian of f_zero_1 on x1\n",
    "    x1 = randn(2)\n",
    "    @info \"this error is expected:\"\n",
    "    try \n",
    "        ForwardDiff.jacobian(f_zero_1,x1)\n",
    "    catch e \n",
    "        buf = IOBuffer()\n",
    "        showerror(buf,e)\n",
    "        message = String(take!(buf))\n",
    "        Base.showerror(stdout,e)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-afghanistan",
   "metadata": {},
   "source": [
    "This is the most common ForwardDiff error that you will encounter. ForwardDiff works by pushing `ForwardDiff.Dual` variables through the function being differentiated. Normally this works without issue, but if you create a vector of `Float64` (like you would with `xdot = zeros(5)`, it is unable to fit the `ForwardDiff.Dual`'s in with the `Float64`'s. To get around this, you have two options:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-oregon",
   "metadata": {},
   "source": [
    "### Option 1 \n",
    "Our first option is just creating xdot directly, without creating an array of zeros to index into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this block is a tutorial, you do not have to fill anything out. \n",
    "function f_zero_1(x)\n",
    "    \n",
    "    # let's create xdot directly, without first making a vector of zeros \n",
    "    xdot = [x[1]*x[2], x[2]^2]\n",
    "    \n",
    "    # NOTE: the compiler figures out which type to make xdot, so when you call the function normally\n",
    "    # it's a Float64, and when it's being diffed, it's automatically promoted to a ForwardDiff.Dual type\n",
    "\n",
    "    return xdot \n",
    "end\n",
    "\n",
    "let \n",
    "    # try and calculate the jacobian of f_zero_1 on x1\n",
    "    x1 = randn(2)\n",
    "    ForwardDiff.jacobian(f_zero_1,x1) # this will work\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-cause",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "The second option is to create the array of zeros in a way that accounts for the input type. This can be done by replacing `zeros(length(x))` with `zeros(eltype(x),length(x))`. The first argument `eltype(x)` simply creates a vector of zeros that is the same type as the element type in vector x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this block is a tutorial, you do not have to fill anything out. \n",
    "function f_zero_1(x)\n",
    "    \n",
    "    # diffing through this function will error on this line \n",
    "    xdot = zeros(eltype(x), length(x))\n",
    "    \n",
    "    xdot[1] = x[1]*x[2]\n",
    "    xdot[2] = x[2]^2\n",
    "    \n",
    "    return xdot \n",
    "end\n",
    "\n",
    "let \n",
    "    # try and calculate the jacobian of f_zero_1 on x1\n",
    "    x1 = randn(2)\n",
    "    ForwardDiff.jacobian(f_zero_1,x1) # this will fail! \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-transport",
   "metadata": {},
   "source": [
    "Now you can show that you understand these two options by fixing two broken functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix this error when trying to diff through this function\n",
    "# hint: you can use eltype([x;u]) to return the correct type if either x or u is a ForwardDiff.Dual (option 2)\n",
    "\n",
    "function dynamics(x,u)\n",
    "    ẋ = zeros(length(x))\n",
    "    ẋ[1] = x[1]*sin(u[1])\n",
    "    ẋ[2] = x[2]*cos(u[2])\n",
    "    return ẋ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"1d\" begin                                     # POINTS = 2\n",
    "    x = [.1;.4]\n",
    "    u = [.2;-.3]\n",
    "    A = ForwardDiff.jacobian(_x -> dynamics(_x,u),x) \n",
    "    B = ForwardDiff.jacobian(_u -> dynamics(x,_u),u) \n",
    "    @test typeof(A) == Matrix{Float64}                  # POINTS = 1\n",
    "    @test typeof(B) == Matrix{Float64}                  # POINTS = 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-peace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
